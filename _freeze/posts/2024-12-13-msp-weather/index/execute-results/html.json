{
  "hash": "b8e43d182d4de45138bd68fc89f5a7d7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Analyzing weather trends in Minnesota\"\ndescription: \"Following extreme weather events at the Minneapolis-Saint Paul International Airport\"\nauthor:\n  - name: Liz Peterson\n    url: https://egp4aq.github.io/\n    orcid: 0000-0002-5300-3075\n    affiliation: MEDS\n    affiliation-url: https://bren.ucsb.edu/masters-programs/master-environmental-data-science\ndate: 2024-12-13\ntoc: true\nimage: pioneer_press_image.png\ncitation:\n  url: https://egp4aq.github.io/posts/2024-12-10-msp-weather\nexecute: \n  eval: true\n  message: false\n  warning: false\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n### Before we begin\n\nHere is the link to the github repository where all of the data and code is housed:\n\n[msp-weather repository](https://github.com/egp4aq/msp-weather)\n\n## Introduction\n\nOn Halloween 1991, a massive blizzard hit Minnesota. This event has lived on in cultural infamy among Minnesotans. Of the 25 top snowfall events in Minnesota (from 1884-2023), only 5 of them occurred in the 21st century. There seems to be a trend away from high intensity snowfall events. This is a curious question: as the onset of climate change raises temperatures and increases the occurrence of extreme weather events, what does this mean for blizzards and intense snowfall events? Are there fewer intense snowfall events? Is that correlated to an increase in atmospheric CO2? And, if so, does that align with other trends we see in weather patterns?\n\nAs the general public becomes more worried about the reality of what a warming planet means for them, more research about how climate change might influence weather patterns is being conducted. There are studies analyzing what a warmer planet means for snowfall events, but these are mostly looking at worldwide trends. This analysis aims to see how this is working in Minnesota, a place where snow has a lot of cultural meaning. \n\n## Notebook set up \n\nIn order to set up our notebook, we need to read in our essential packages. The packages needed for this analysis are `here` for reading in the data, `hockeystick` for accessing some of the data for this project, `tidyverse` and `ggplot2` for cleaning, analyzing and visualizing the data, and `kableExtra` and `broom` for making our results neat.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Open code\"}\n# Load required packages\nlibrary(here)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(hockeystick)\nlibrary(kableExtra)\nlibrary(broom)\n```\n:::\n\n\n\n## Data details\n\nTo examine these questions, we will need to gather some important data: extensive weather and precipitation data from Minnesota, atmospheric CO2 concentration data, and some information about specific snowfall events.\n\nThe precipitation data came from NOAA's National Centers for Environmental Information. While this platform has a huge volume of data from all over, you are only allowed to request said data in 10 year chunks. Therefore, the chunks of data I downloaded were: 1985/01/01 - 1994/01/01, 1994/01/02 - 2003/12/31, 2004/01/01 - 2013/12/31, and 2014/01/01 - 2023/12/31. The weather station where the data was recorded was the Minneapolis Saint Paul international airport, which is located in Southeast Minnesota. Find this data, or conduct a search for any other weather station data, [here](https://www.ncdc.noaa.gov/cdo-web/search;jsessionid=4B32D1D356346119BA199C8252EEA6A6).\n\nThe atmospheric CO2 data comes from an R package called hockeystick. The package is very robust with all sorts of climate adjacent information. This includes atmospheric CO2, methane, emissions, instrumental and proxy temperature records, sea levels, Arctic/Antarctic sea-ice, Hurricanes, and Paleo climate data. This is a very accessible way to begin making climate models with open source software. To get more information about this package, read the package's documentation [here](https://cran.r-project.org/web/packages/hockeystick/readme/README.html).\n\nTo make analysis easier, when we read in the data, we are going to do some cleaning immediately. We will use janitor to transform all of the column names in the the weather data to lower snake case. The data also comes with a lot of columns and observations of weather phenomena, but we are only interested in the hourly precipitation data, so we will drop all other columns. Additionally, for a few of the data, the hourly precipitation data is not numeric, so we will make sure to change that column to be of type numeric. \n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Open code\"}\n# Read in weather data\n# 1985/01/01 - 1994/01/01\nweather_1985_1994 <- read_csv(here('posts/2024-12-13-msp-weather/data/85-94.csv')) %>% # Read in csv\n  janitor::clean_names() %>% # convert column names to lower snake case\n  select(station, date, hourly_precipitation) %>% # select only columns we are interested in\n  mutate(hourly_precipitation = as.numeric(hourly_precipitation))\n\n# 1994/01/02 - 2003/12/31\nweather_1994_2003 <- read_csv(here('posts/2024-12-13-msp-weather/data/94-03.csv')) %>%\n  janitor::clean_names() %>%\n  select(station, date, hourly_precipitation) %>%\n  mutate(hourly_precipitation = as.numeric(hourly_precipitation))\n\n# 2004/01/01 - 2013/12/31\nweather_2004_2014 <- read_csv(here('posts/2024-12-13-msp-weather/data/04-14.csv')) %>%\n  janitor::clean_names() %>%\n  select(station, date, hourly_precipitation) %>%\n  mutate(hourly_precipitation = as.numeric(hourly_precipitation))\n\n# 2014/01/01 - 2023/12/31\nweather_2014_2023 <- read_csv(here('posts/2024-12-13-msp-weather/data/14-23.csv')) %>%\n  janitor::clean_names() %>%\n  select(station, date, hourly_precipitation) %>%\n  mutate(hourly_precipitation = as.numeric(hourly_precipitation))\n```\n:::\n\n\n\nReading in the CO2 data is much simpler, because of the hockeystick package in R. \n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Open code\"}\n# Read in emissions data\nco2 <- get_carbon()\n```\n:::\n\n\n\n## Initial analysis\n\nNow that we have both our precipitation and CO2 data, we need to aggregate and filter the data for our analysis purposes. \n\nFirst, we will combine the four chunks of weather data into one data set. Then we will take that combined data and aggregate it to get the monthly average precipitation. To do this, we need to pull out the month from the date datetime object, and then take the average in those specific month groups. To help with this analysis, we will add in a period column when we combine the data in order to differentiate the chunks.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Open code\"}\n# Combine all datasets into one and add a period column\ncombined_weather_data <- bind_rows(\n  weather_1985_1994 %>% mutate(period = \"1985-1994\"),\n  weather_1994_2003 %>% mutate(period = \"1994-2003\"),\n  weather_2004_2014 %>% mutate(period = \"2004-2014\"),\n  weather_2014_2023 %>% mutate(period = \"2014-2023\")\n)\n\n# Aggregate data to get monthly precipitation\nmonthly_avg_combined <- combined_weather_data %>%\n  mutate(date = as.Date(date),  # Ensure 'date' is in Date format\n         year_month = floor_date(date, \"month\")) %>%  # Create year_month column --> floor_date from lubridate\n  group_by(period, year_month) %>%  # Group by both 'period' and 'year_month'\n  summarize(monthly_avg_precip = mean(hourly_precipitation, na.rm = TRUE))  # Calculate monthly average\n```\n:::\n\n\n\nWe want to create an object for the specific date of the 1991 Halloween blizzard for visualization purposes. We want to make sure that this is a datetime object.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Open code\"}\n# Specify date of Halloween blizzard\nhighlight_date <- as.Date(\"1991-10-31\")\n```\n:::\n\n\n\nLastly, we want to filter the CO2 data to only include the data from 1985 - 2023, our time frame of interest. This filtering is made quite easy because of how tidy the CO2 data is in the hockeystick package.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Open code\"}\nco2 <- co2 %>%\n  filter(year >= 1985 & year <= 2023)\n```\n:::\n\n\n\n## Initial visualizations\n\nFirst, let's visualize the trend of the atmospheric CO2 content over the years using ggplot.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Open code\"}\nggplot(co2, aes(x = year, y = average)) +\n  geom_line() +\n  theme_minimal() +\n  labs(title = \"Atmospheric CO2 content by year\",\n    x = \"Year\",\n    y = \"Atmospheric CO2\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\nWe see from this plot that there is almost an exponential increase in atmospheric CO2 content from the year 1985 to 2023. Although the trends for emissions have not kept up in the same fashion, the amount in the atmosphere has not fallen in the same way. \n\nNext, let's visualize the precipitation data over our whole time frame. We'll do this by using the monthly average precipitation we calculated above. The dotted line points out when the blizzard occurred, the highlight date that we created before.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Open code\"}\n# Plot combined data\nggplot(monthly_avg_combined, aes(x = year_month, y = monthly_avg_precip, color = period)) +\n  geom_line() +\n  scale_x_date(date_labels = \"%b %Y\", date_breaks = \"18 months\") +  # Format x-axis labels\n  labs(title = \"Monthly Average Precipitation by Period\",\n    x = \"Date\",\n    y = \"Monthly Average Precipitation (mm)\",\n    color = \"Period\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  geom_vline(aes(xintercept = highlight_date), color = \"black\", linetype = \"dashed\", size = 0.3)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\nWe see from this plot that there is some sort of upward trend in precipitation. Additionally, it seems that months with high precipitation have higher peaks than they used to. In fact, when the blizzard happened, the monthly precipitation was still much lower than months in the 21st century. \n\n## Combined analysis\n\nNow that we have our preliminary plots, we want to do some analysis with the two data sets together. To do this, we are going to merge the data sets. However, in order to do this, we need to aggregate the precipitation averages again to be yearly averages rather than monthly. We will do this in the same way that we did the monthly averages, but with the year object rather than month. Once we do that, we can join the two data sets on the year column. \n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Open code\"}\n#  aggregate the monthly precipitation data to be yearly data so we can merge it with the yearly us emissions data\nyearly_avg_precip <- monthly_avg_combined %>%\n  mutate(year = as.numeric(format(year_month, \"%Y\"))) %>%\n  group_by(year) %>%\n  summarize(yearly_avg_precip = mean(monthly_avg_precip, na.rm = TRUE))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Open code\"}\n# merge the us_emissions data and the precipitation data and get rid of the columns we don't need\nprecip_co2 <- left_join(yearly_avg_precip, co2, by = \"year\") %>%\n  select(year, yearly_avg_precip, average)\n```\n:::\n\n\n\n## Run our model\n\nIn order to visualize the relationship between the yearly average precipitation and atmospheric CO2, we need to use a gamma regression rather than the classic linear regression. Gamma regression is commonly used in distributions where the variable cannot be negative, like our precipitation data. A linear regression model assumes that the disturbances or errors are normally distributed around zero, which is impossible for our model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Open code\"}\n# Gamma regression\ngamma_model <- glm(yearly_avg_precip ~ average, data = precip_co2, family = Gamma(link = \"log\"))\nsummary(gamma_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = yearly_avg_precip ~ average, family = Gamma(link = \"log\"), \n    data = precip_co2)\n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -1.144e+01  2.032e-01  -56.28   <2e-16 ***\naverage      1.643e-02  5.341e-04   30.77   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.06652693)\n\n    Null deviance: 91.015  on 467  degrees of freedom\nResidual deviance: 33.274  on 466  degrees of freedom\nAIC: -4794.3\n\nNumber of Fisher Scoring iterations: 5\n```\n\n\n:::\n:::\n\n\n\nNow that we've run our model, let's see what it looks like visually.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Open code\"}\n# Plot the data with regression line\nggplot(precip_co2, aes(x = average, y = yearly_avg_precip)) +\n  geom_point() +\n  geom_smooth(method = \"glm\", \n              method.args = list(family = Gamma(link = \"log\")), \n              se = FALSE, \n              color = \"blue\") +\n  labs(title = \"Relationship between Atmospheric CO2 and Precipitation\",\n    x = \"Atmospheric CO2\",\n    y = \"Yearly Average Precipitation (mm)\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\nThe model seems to fit our data very well. The trend seems to support our initial hypothesis from the very beginning: that an increase in atmospheric CO2 content would be correlated to an increase in precipitation events. \n\n## Hypothesis testing\n\nNow that we have our model, we will utilize hypothesis testing to evaluate how much we can rely on this model. To hypothesize on our gamma model, we will begin by formulating null and alternate hypotheses. The null hypothesis (or H0) is that there is no relationship between atmospheric CO2 and precipitation. The alternative hypothesis (or H1) is that there is a significant relationship between atmospheric CO2 and precipitation. \n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Open code\"}\n# Gamma regression\ngamma_model <- glm(yearly_avg_precip ~ average, data = precip_co2, family = Gamma(link = \"log\"))\nresults <- tidy(gamma_model)\nresults$p.value <- sprintf(\"%.15f\", results$p.value)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Open code\"}\nresults %>%\n  kable(\"html\", caption = \"Regression Model Results\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), full_width = FALSE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Regression Model Results</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> estimate </th>\n   <th style=\"text-align:right;\"> std.error </th>\n   <th style=\"text-align:right;\"> statistic </th>\n   <th style=\"text-align:left;\"> p.value </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> -11.4392318 </td>\n   <td style=\"text-align:right;\"> 0.2032374 </td>\n   <td style=\"text-align:right;\"> -56.28508 </td>\n   <td style=\"text-align:left;\"> 0.000000000000000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> average </td>\n   <td style=\"text-align:right;\"> 0.0164338 </td>\n   <td style=\"text-align:right;\"> 0.0005341 </td>\n   <td style=\"text-align:right;\"> 30.77173 </td>\n   <td style=\"text-align:left;\"> 0.000000000000000 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\nAs we look at the results from the the gamma model, our p value is 0.000... Above, we have the p value rounded to 15 decimal points, for simplicity's sake. I did have it previously rounded to 30 decimal points, and still they remained at zero. Therefore, with a p value of 0, which is less than 0.05, we can reject the null hypothesis. This tells us that there is a significant relationship between atmospheric CO2 content and average precipitation. \n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Open code\"}\nconfint(gamma_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  2.5 %       97.5 %\n(Intercept) -11.8555695 -11.02272832\naverage       0.0153399   0.01752871\n```\n\n\n:::\n:::\n\n\n\nWhen we run our confidence interval for the intercept, we get [-11.85554125 -11.02269481] (for a 2.5%/97.5% split). This means that we can be 97.5% sure that the true intercept falls within that range. More importantly for our CO2 variable we get [0.01533981 0.01752864]. This means that we are 97.5% confident that the true value for our gamma regression falls within that range. While that range is higher than zero, it still does fall below that 0.05 range, giving us further confidence in our model. \n\n## Next steps\n\nWhile this analysis does take an in depth look into precipitation trends in the last 30 years in the Minneapolis, Saint Paul area as it relates to climate change, there are a couple of additions to the study that could be a great jumping off point for further research. To begin, climate change by nature is a study best done in the long term. When you look too microscopically at weather trends, they are simply that: weather, not climate. On that note, doing this analysis on a larger time scale might allow for more nuance in the results. Additionally, it is difficult to get a measure of these high intensity storm events specifically without simply looking at average precipitation, as I did here. Perhaps future studies could look at those events more specifically within these trends. Lastly, adding another geographic element could be an interesting avenue to explore. Minnesota is near and dear to my heart, which is why I chose it. I would be interested, however, to see how these trends might differ across the country and even the world.\n\n### References\n\nChavez, A., & Jansen, J. (2021). hockeystick: Simple tools for creating hockey stick plots. Comprehensive R Archive Network (CRAN). https://cran.r-project.org/web/packages/hockeystick/readme/README.html\n\nDoyle, A. (2021, October 29). Remembering the 1991 Halloween blizzard. TwinCities.com. Retrieved December 10, 2024, from https://www.twincities.com/2021/10/29/remembering-the-1991-halloween-blizzard/\n\nNational Oceanic and Atmospheric Administration. Search for climate data. National Centers for Environmental Information. https://www.ncdc.noaa.gov/cdo-web/search\n\nUniversity of Virginia Library. Getting started with Gamma regression. University of Virginia Library. https://library.virginia.edu/data/articles/getting-started-with-gamma-regression\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}