[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Masters of Environmental Data Science (Bren School of Environmental Science and Management at UCSB 2025)\nBachelors of Arts in Environmental Science with a Minor in Data Science (UVA 2024)"
  },
  {
    "objectID": "about.html#my-education",
    "href": "about.html#my-education",
    "title": "About",
    "section": "",
    "text": "Masters of Environmental Data Science (Bren School of Environmental Science and Management at UCSB 2025)\nBachelors of Arts in Environmental Science with a Minor in Data Science (UVA 2024)"
  },
  {
    "objectID": "about.html#my-work",
    "href": "about.html#my-work",
    "title": "About",
    "section": "My work",
    "text": "My work\nDuring my undergraduate career, I worked for the Charlottesville Community Climate Collaborative as a Climate Justice Ambassador. My small group of Ambassadors conducted a study on natural gas use in Charlottesville, engaging with community members to explore the impacts of energy cost on their daily lives.\nOn campus, I logged 268 hours volunteering at HelpLine, a student-run crisis hotline, as both a volunteer and a trainer.\nI also worked for the Contemplative Sciences Center at UVA, where I dedicated time to helping students and faculty access resources to thrive internally."
  },
  {
    "objectID": "about.html#my-fun",
    "href": "about.html#my-fun",
    "title": "About",
    "section": "My fun",
    "text": "My fun\nI love a Japanese skill toy called the kendama. There are always new tricks to learn! As shown in my first blog post, I am new to the Santa Barbara area and California in general. I have loved exploring by hiking, swimming, and surfing. Though I am always wary of calling myself a “big reader” or a “film buff” as people find a lot of pride and identity in these terms, I do love reading and watching movies. This past year, I have discovered the joy of logging and rating books and movies. I’ve attached my goodreads and letterboxd so you can judge my tastes. Perhaps it’s just another way for me to collect as much data as possible."
  },
  {
    "objectID": "posts/2024-10-18-my-first-post/index.html",
    "href": "posts/2024-10-18-my-first-post/index.html",
    "title": "How to get from Falls Church, VA to Santa Barbara, CA",
    "section": "",
    "text": "Have you ever asked yourself, how would I go about getting from Falls Church, Virginia to Santa Barbara, California? As a young woman experiencing her assent into adulthood, I too was faced with this age old question. To save you the trouble, I will share what I learned on this quest."
  },
  {
    "objectID": "posts/2024-10-18-my-first-post/index.html#from-virginia-to-minnesota-i-cant-offer-much-more-than-this",
    "href": "posts/2024-10-18-my-first-post/index.html#from-virginia-to-minnesota-i-cant-offer-much-more-than-this",
    "title": "How to get from Falls Church, VA to Santa Barbara, CA",
    "section": "From Virginia to Minnesota, I can’t offer much more than this",
    "text": "From Virginia to Minnesota, I can’t offer much more than this\nThis drive is all to familiar to me, so I offer only this."
  },
  {
    "objectID": "posts/2024-10-18-my-first-post/index.html#corn-palace",
    "href": "posts/2024-10-18-my-first-post/index.html#corn-palace",
    "title": "How to get from Falls Church, VA to Santa Barbara, CA",
    "section": "CORN PALACE",
    "text": "CORN PALACE\nAs a Midwesterner at heart, and a long time admirer of the butter sculpture at the Minnesota State Fair, this palace of corn appealed to me greatly."
  },
  {
    "objectID": "posts/2024-10-18-my-first-post/index.html#mount-rushmore",
    "href": "posts/2024-10-18-my-first-post/index.html#mount-rushmore",
    "title": "How to get from Falls Church, VA to Santa Barbara, CA",
    "section": "MOUNT RUSHMORE",
    "text": "MOUNT RUSHMORE\nIt’s quite peculiar. You think that there might some big monumental moment (pun intended), but there’s not. It really is just 4 heads carved into this rock! However, it is very beautiful. Maybe just a bit smaller than anticipated."
  },
  {
    "objectID": "posts/2024-10-18-my-first-post/index.html#arches-national-park",
    "href": "posts/2024-10-18-my-first-post/index.html#arches-national-park",
    "title": "How to get from Falls Church, VA to Santa Barbara, CA",
    "section": "ARCHES NATIONAL PARK",
    "text": "ARCHES NATIONAL PARK\nIt’s hard to describe the elation I felt running around on these red rocks after so many days in the car. I felt like I was nearly bouncing."
  },
  {
    "objectID": "posts/2024-10-18-my-first-post/index.html#grand-canyon",
    "href": "posts/2024-10-18-my-first-post/index.html#grand-canyon",
    "title": "How to get from Falls Church, VA to Santa Barbara, CA",
    "section": "GRAND CANYON",
    "text": "GRAND CANYON\nIt truly is grand. As we were approaching, we saw a lot of canyons. We kept asking ourselves… is that it? Are we sure we’re going to know when we’re there? We certainly did. It’s quite unmissable."
  },
  {
    "objectID": "posts/2024-10-18-my-first-post/index.html#we-made-it",
    "href": "posts/2024-10-18-my-first-post/index.html#we-made-it",
    "title": "How to get from Falls Church, VA to Santa Barbara, CA",
    "section": "We made it",
    "text": "We made it\nBoy oh boy was I nervous to see this sign. I’m not sure that those nerves subsided for a couple of days. But look at us now :)"
  },
  {
    "objectID": "posts/2024-12-13-msp-weather/index.html",
    "href": "posts/2024-12-13-msp-weather/index.html",
    "title": "Analyzing weather trends in Minnesota",
    "section": "",
    "text": "Here is the link to the github repository where all of the data and code is housed:\nmsp-weather repository"
  },
  {
    "objectID": "posts/2024-12-13-msp-weather/index.html#introduction",
    "href": "posts/2024-12-13-msp-weather/index.html#introduction",
    "title": "Analyzing weather trends in Minnesota",
    "section": "Introduction",
    "text": "Introduction\nOn Halloween 1991, a massive blizzard hit Minnesota. This event has lived on in cultural infamy among Minnesotans. Of the 25 top snowfall events in Minnesota (from 1884-2023), only 5 of them occurred in the 21st century. There seems to be a trend away from high intensity snowfall events. This is a curious question: as the onset of climate change raises temperatures and increases the occurrence of extreme weather events, what does this mean for blizzards and intense snowfall events? Are there fewer intense snowfall events? Is that correlated to an increase in atmospheric CO2? And, if so, does that align with other trends we see in weather patterns?\nAs the general public becomes more worried about the reality of what a warming planet means for them, more research about how climate change might influence weather patterns is being conducted. There are studies analyzing what a warmer planet means for snowfall events, but these are mostly looking at worldwide trends. This analysis aims to see how this is working in Minnesota, a place where snow has a lot of cultural meaning."
  },
  {
    "objectID": "posts/2024-12-13-msp-weather/index.html#notebook-set-up",
    "href": "posts/2024-12-13-msp-weather/index.html#notebook-set-up",
    "title": "Analyzing weather trends in Minnesota",
    "section": "Notebook set up",
    "text": "Notebook set up\nIn order to set up our notebook, we need to read in our essential packages. The packages needed for this analysis are here for reading in the data, hockeystick for accessing some of the data for this project, tidyverse and ggplot2 for cleaning, analyzing and visualizing the data, and kableExtra and broom for making our results neat.\n\n\nOpen code\n# Load required packages\nlibrary(here)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(hockeystick)\nlibrary(kableExtra)\nlibrary(broom)"
  },
  {
    "objectID": "posts/2024-12-13-msp-weather/index.html#data-details",
    "href": "posts/2024-12-13-msp-weather/index.html#data-details",
    "title": "Analyzing weather trends in Minnesota",
    "section": "Data details",
    "text": "Data details\nTo examine these questions, we will need to gather some important data: extensive weather and precipitation data from Minnesota, atmospheric CO2 concentration data, and some information about specific snowfall events.\nThe precipitation data came from NOAA’s National Centers for Environmental Information. While this platform has a huge volume of data from all over, you are only allowed to request said data in 10 year chunks. Therefore, the chunks of data I downloaded were: 1985/01/01 - 1994/01/01, 1994/01/02 - 2003/12/31, 2004/01/01 - 2013/12/31, and 2014/01/01 - 2023/12/31. The weather station where the data was recorded was the Minneapolis Saint Paul international airport, which is located in Southeast Minnesota. Find this data, or conduct a search for any other weather station data, here.\nThe atmospheric CO2 data comes from an R package called hockeystick. The package is very robust with all sorts of climate adjacent information. This includes atmospheric CO2, methane, emissions, instrumental and proxy temperature records, sea levels, Arctic/Antarctic sea-ice, Hurricanes, and Paleo climate data. This is a very accessible way to begin making climate models with open source software. To get more information about this package, read the package’s documentation here.\nTo make analysis easier, when we read in the data, we are going to do some cleaning immediately. We will use janitor to transform all of the column names in the the weather data to lower snake case. The data also comes with a lot of columns and observations of weather phenomena, but we are only interested in the hourly precipitation data, so we will drop all other columns. Additionally, for a few of the data, the hourly precipitation data is not numeric, so we will make sure to change that column to be of type numeric.\n\n\nOpen code\n# Read in weather data\n# 1985/01/01 - 1994/01/01\nweather_1985_1994 &lt;- read_csv(here('posts/2024-12-13-msp-weather/data/85-94.csv')) %&gt;% # Read in csv\n  janitor::clean_names() %&gt;% # convert column names to lower snake case\n  select(station, date, hourly_precipitation) %&gt;% # select only columns we are interested in\n  mutate(hourly_precipitation = as.numeric(hourly_precipitation))\n\n# 1994/01/02 - 2003/12/31\nweather_1994_2003 &lt;- read_csv(here('posts/2024-12-13-msp-weather/data/94-03.csv')) %&gt;%\n  janitor::clean_names() %&gt;%\n  select(station, date, hourly_precipitation) %&gt;%\n  mutate(hourly_precipitation = as.numeric(hourly_precipitation))\n\n# 2004/01/01 - 2013/12/31\nweather_2004_2014 &lt;- read_csv(here('posts/2024-12-13-msp-weather/data/04-14.csv')) %&gt;%\n  janitor::clean_names() %&gt;%\n  select(station, date, hourly_precipitation) %&gt;%\n  mutate(hourly_precipitation = as.numeric(hourly_precipitation))\n\n# 2014/01/01 - 2023/12/31\nweather_2014_2023 &lt;- read_csv(here('posts/2024-12-13-msp-weather/data/14-23.csv')) %&gt;%\n  janitor::clean_names() %&gt;%\n  select(station, date, hourly_precipitation) %&gt;%\n  mutate(hourly_precipitation = as.numeric(hourly_precipitation))\n\n\nReading in the CO2 data is much simpler, because of the hockeystick package in R.\n\n\nOpen code\n# Read in emissions data\nco2 &lt;- get_carbon()"
  },
  {
    "objectID": "posts/2024-12-13-msp-weather/index.html#initial-analysis",
    "href": "posts/2024-12-13-msp-weather/index.html#initial-analysis",
    "title": "Analyzing weather trends in Minnesota",
    "section": "Initial analysis",
    "text": "Initial analysis\nNow that we have both our precipitation and CO2 data, we need to aggregate and filter the data for our analysis purposes.\nFirst, we will combine the four chunks of weather data into one data set. Then we will take that combined data and aggregate it to get the monthly average precipitation. To do this, we need to pull out the month from the date datetime object, and then take the average in those specific month groups. To help with this analysis, we will add in a period column when we combine the data in order to differentiate the chunks.\n\n\nOpen code\n# Combine all datasets into one and add a period column\ncombined_weather_data &lt;- bind_rows(\n  weather_1985_1994 %&gt;% mutate(period = \"1985-1994\"),\n  weather_1994_2003 %&gt;% mutate(period = \"1994-2003\"),\n  weather_2004_2014 %&gt;% mutate(period = \"2004-2014\"),\n  weather_2014_2023 %&gt;% mutate(period = \"2014-2023\")\n)\n\n# Aggregate data to get monthly precipitation\nmonthly_avg_combined &lt;- combined_weather_data %&gt;%\n  mutate(date = as.Date(date),  # Ensure 'date' is in Date format\n         year_month = floor_date(date, \"month\")) %&gt;%  # Create year_month column --&gt; floor_date from lubridate\n  group_by(period, year_month) %&gt;%  # Group by both 'period' and 'year_month'\n  summarize(monthly_avg_precip = mean(hourly_precipitation, na.rm = TRUE))  # Calculate monthly average\n\n\nWe want to create an object for the specific date of the 1991 Halloween blizzard for visualization purposes. We want to make sure that this is a datetime object.\n\n\nOpen code\n# Specify date of Halloween blizzard\nhighlight_date &lt;- as.Date(\"1991-10-31\")\n\n\nLastly, we want to filter the CO2 data to only include the data from 1985 - 2023, our time frame of interest. This filtering is made quite easy because of how tidy the CO2 data is in the hockeystick package.\n\n\nOpen code\nco2 &lt;- co2 %&gt;%\n  filter(year &gt;= 1985 & year &lt;= 2023)"
  },
  {
    "objectID": "posts/2024-12-13-msp-weather/index.html#initial-visualizations",
    "href": "posts/2024-12-13-msp-weather/index.html#initial-visualizations",
    "title": "Analyzing weather trends in Minnesota",
    "section": "Initial visualizations",
    "text": "Initial visualizations\nFirst, let’s visualize the trend of the atmospheric CO2 content over the years using ggplot.\n\n\nOpen code\nggplot(co2, aes(x = year, y = average)) +\n  geom_line() +\n  theme_minimal() +\n  labs(title = \"Atmospheric CO2 content by year\",\n    x = \"Year\",\n    y = \"Atmospheric CO2\")\n\n\n\n\n\n\n\n\n\nWe see from this plot that there is almost an exponential increase in atmospheric CO2 content from the year 1985 to 2023. Although the trends for emissions have not kept up in the same fashion, the amount in the atmosphere has not fallen in the same way.\nNext, let’s visualize the precipitation data over our whole time frame. We’ll do this by using the monthly average precipitation we calculated above. The dotted line points out when the blizzard occurred, the highlight date that we created before.\n\n\nOpen code\n# Plot combined data\nggplot(monthly_avg_combined, aes(x = year_month, y = monthly_avg_precip, color = period)) +\n  geom_line() +\n  scale_x_date(date_labels = \"%b %Y\", date_breaks = \"18 months\") +  # Format x-axis labels\n  labs(title = \"Monthly Average Precipitation by Period\",\n    x = \"Date\",\n    y = \"Monthly Average Precipitation (mm)\",\n    color = \"Period\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  geom_vline(aes(xintercept = highlight_date), color = \"black\", linetype = \"dashed\", size = 0.3)\n\n\n\n\n\n\n\n\n\nWe see from this plot that there is some sort of upward trend in precipitation. Additionally, it seems that months with high precipitation have higher peaks than they used to. In fact, when the blizzard happened, the monthly precipitation was still much lower than months in the 21st century."
  },
  {
    "objectID": "posts/2024-12-13-msp-weather/index.html#combined-analysis",
    "href": "posts/2024-12-13-msp-weather/index.html#combined-analysis",
    "title": "Analyzing weather trends in Minnesota",
    "section": "Combined analysis",
    "text": "Combined analysis\nNow that we have our preliminary plots, we want to do some analysis with the two data sets together. To do this, we are going to merge the data sets. However, in order to do this, we need to aggregate the precipitation averages again to be yearly averages rather than monthly. We will do this in the same way that we did the monthly averages, but with the year object rather than month. Once we do that, we can join the two data sets on the year column.\n\n\nOpen code\n#  aggregate the monthly precipitation data to be yearly data so we can merge it with the yearly us emissions data\nyearly_avg_precip &lt;- monthly_avg_combined %&gt;%\n  mutate(year = as.numeric(format(year_month, \"%Y\"))) %&gt;%\n  group_by(year) %&gt;%\n  summarize(yearly_avg_precip = mean(monthly_avg_precip, na.rm = TRUE))\n\n\n\n\nOpen code\n# merge the us_emissions data and the precipitation data and get rid of the columns we don't need\nprecip_co2 &lt;- left_join(yearly_avg_precip, co2, by = \"year\") %&gt;%\n  select(year, yearly_avg_precip, average)"
  },
  {
    "objectID": "posts/2024-12-13-msp-weather/index.html#run-our-model",
    "href": "posts/2024-12-13-msp-weather/index.html#run-our-model",
    "title": "Analyzing weather trends in Minnesota",
    "section": "Run our model",
    "text": "Run our model\nIn order to visualize the relationship between the yearly average precipitation and atmospheric CO2, we need to use a gamma regression rather than the classic linear regression. Gamma regression is commonly used in distributions where the variable cannot be negative, like our precipitation data. A linear regression model assumes that the disturbances or errors are normally distributed around zero, which is impossible for our model.\n\n\nOpen code\n# Gamma regression\ngamma_model &lt;- glm(yearly_avg_precip ~ average, data = precip_co2, family = Gamma(link = \"log\"))\nsummary(gamma_model)\n\n\n\nCall:\nglm(formula = yearly_avg_precip ~ average, family = Gamma(link = \"log\"), \n    data = precip_co2)\n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1.144e+01  2.032e-01  -56.28   &lt;2e-16 ***\naverage      1.643e-02  5.341e-04   30.77   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.0665279)\n\n    Null deviance: 91.015  on 467  degrees of freedom\nResidual deviance: 33.274  on 466  degrees of freedom\nAIC: -4794.3\n\nNumber of Fisher Scoring iterations: 5\n\n\nNow that we’ve run our model, let’s see what it looks like visually.\n\n\nOpen code\n# Plot the data with regression line\nggplot(precip_co2, aes(x = average, y = yearly_avg_precip)) +\n  geom_point() +\n  geom_smooth(method = \"glm\", \n              method.args = list(family = Gamma(link = \"log\")), \n              se = FALSE, \n              color = \"blue\") +\n  labs(title = \"Relationship between Atmospheric CO2 and Precipitation\",\n    x = \"Atmospheric CO2\",\n    y = \"Yearly Average Precipitation (mm)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe model seems to fit our data very well. The trend seems to support our initial hypothesis from the very beginning: that an increase in atmospheric CO2 content would be correlated to an increase in precipitation events."
  },
  {
    "objectID": "posts/2024-12-13-msp-weather/index.html#hypothesis-testing",
    "href": "posts/2024-12-13-msp-weather/index.html#hypothesis-testing",
    "title": "Analyzing weather trends in Minnesota",
    "section": "Hypothesis testing",
    "text": "Hypothesis testing\nNow that we have our model, we will utilize hypothesis testing to evaluate how much we can rely on this model. To hypothesize on our gamma model, we will begin by formulating null and alternate hypotheses. The null hypothesis (or H0) is that there is no relationship between atmospheric CO2 and precipitation. The alternative hypothesis (or H1) is that there is a significant relationship between atmospheric CO2 and precipitation.\n\n\nOpen code\n# Gamma regression\ngamma_model &lt;- glm(yearly_avg_precip ~ average, data = precip_co2, family = Gamma(link = \"log\"))\nresults &lt;- tidy(gamma_model)\nresults$p.value &lt;- sprintf(\"%.15f\", results$p.value)\n\n\n\n\nOpen code\nresults %&gt;%\n  kable(\"html\", caption = \"Regression Model Results\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), full_width = FALSE)\n\n\n\nRegression Model Results\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-11.4392009\n0.2032386\n-56.2846\n0.000000000000000\n\n\naverage\n0.0164337\n0.0005341\n30.7714\n0.000000000000000\n\n\n\n\n\n\n\nAs we look at the results from the the gamma model, our p value is 0.000… Above, we have the p value rounded to 15 decimal points, for simplicity’s sake. I did have it previously rounded to 30 decimal points, and still they remained at zero. Therefore, with a p value of 0, which is less than 0.05, we can reject the null hypothesis. This tells us that there is a significant relationship between atmospheric CO2 content and average precipitation.\n\n\nOpen code\nconfint(gamma_model)\n\n\n                   2.5 %       97.5 %\n(Intercept) -11.85554125 -11.02269481\naverage       0.01533981   0.01752864\n\n\nWhen we run our confidence interval for the intercept, we get [-11.85554125 -11.02269481] (for a 2.5%/97.5% split). This means that we can be 97.5% sure that the true intercept falls within that range. More importantly for our CO2 variable we get [0.01533981 0.01752864]. This means that we are 97.5% confident that the true value for our gamma regression falls within that range. While that range is higher than zero, it still does fall below that 0.05 range, giving us further confidence in our model."
  },
  {
    "objectID": "posts/2024-12-13-msp-weather/index.html#next-steps",
    "href": "posts/2024-12-13-msp-weather/index.html#next-steps",
    "title": "Analyzing weather trends in Minnesota",
    "section": "Next steps",
    "text": "Next steps\nWhile this analysis does take an in depth look into precipitation trends in the last 30 years in the Minneapolis, Saint Paul area as it relates to climate change, there are a couple of additions to the study that could be a great jumping off point for further research. To begin, climate change by nature is a study best done in the long term. When you look too microscopically at weather trends, they are simply that: weather, not climate. On that note, doing this analysis on a larger time scale might allow for more nuance in the results. Additionally, it is difficult to get a measure of these high intensity storm events specifically without simply looking at average precipitation, as I did here. Perhaps future studies could look at those events more specifically within these trends. Lastly, adding another geographic element could be an interesting avenue to explore. Minnesota is near and dear to my heart, which is why I chose it. I would be interested, however, to see how these trends might differ across the country and even the world.\n\nReferences\nChavez, A., & Jansen, J. (2021). hockeystick: Simple tools for creating hockey stick plots. Comprehensive R Archive Network (CRAN). https://cran.r-project.org/web/packages/hockeystick/readme/README.html\nDoyle, A. (2021, October 29). Remembering the 1991 Halloween blizzard. TwinCities.com. Retrieved December 10, 2024, from https://www.twincities.com/2021/10/29/remembering-the-1991-halloween-blizzard/\nNational Oceanic and Atmospheric Administration. Search for climate data. National Centers for Environmental Information. https://www.ncdc.noaa.gov/cdo-web/search\nUniversity of Virginia Library. Getting started with Gamma regression. University of Virginia Library. https://library.virginia.edu/data/articles/getting-started-with-gamma-regression"
  },
  {
    "objectID": "posts/2024-12-02-220-final/thomas_fire_blog_post.html",
    "href": "posts/2024-12-02-220-final/thomas_fire_blog_post.html",
    "title": "Thomas Fire analysis",
    "section": "",
    "text": "Link to github repository\nThe Thomas Fire of December 2017 burned approximately 440 miles squared in Ventura and Santa Barbara counties. It was not fully contained until the the middle of January 2018. This fire had huge implications, as it displaced over 100,000 southern California residents, required the largest deployment of firefighters in California history to combat a wildfire, and cost over $200 million to fight.\nTo analyze the impact of the wildfire, we will look into the implications for air quality in the surrounding areas and how the vegetation was impacted using false color imagery.\n\n\n\nthomas_fire_picture.jpg"
  },
  {
    "objectID": "posts/2024-12-02-220-final/thomas_fire_blog_post.html#air-quality-index-data-analysis",
    "href": "posts/2024-12-02-220-final/thomas_fire_blog_post.html#air-quality-index-data-analysis",
    "title": "Thomas Fire analysis",
    "section": "Air Quality Index data analysis",
    "text": "Air Quality Index data analysis\nBefore we do any analysis, our first step is always to read in our necessary libraries\n\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\nimport xarray as xr\nimport rioxarray as rioxr\n\nFor the AQI data, we are going to read in the csv files directly from their url.\n\n# Read in data from URL\naqi_17 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\", compression='zip')\naqi_18 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\", compression='zip')\n\nNow we can do our analysis! This first part includes cleaning the aqi data, evaluating the rolling average, and plotting our results.\n\nCombine and clean data\nFirst, we bring together our dataframes from 2017 and 2018. Then we clean the column names by putting them all in lower snake case. Finally, we filter the data to only Santa Barbara and drop unnecessary columns.\n\n# Use the concat() function to combine the two dataframes\naqi = pd.concat([aqi_17, aqi_18])\n\n# Simplify column names\naqi.columns = (aqi.columns\n                  .str.lower()\n                  .str.replace(' ','_'))\n\n# Filter to data only from Santa Barbara county\naqi_sb = aqi[aqi['county_name'] == 'Santa Barbara']\n# Drop state_name, county_name, state_code, and county_code columns from dataframe\naqi_sb = aqi_sb.drop(['state_name','county_name','state_code','county_code'], axis = 1)\n\n\n\nTake rolling average of AQI data\nNext, we put the date as the index of our dataframe so that we can use the index to take a rolling average over five days.\n\n# Convert 'date' column to be of type datetime\naqi_sb.date = pd.to_datetime(aqi_sb.date)\naqi_sb = aqi_sb.set_index('date')\n\n# Calculate AQI rolling average over 5 days\nrolling_average = aqi_sb['aqi'].rolling(window = '5D').mean()\n\n# Add a new column which includes the mean AQI for the 5 day rolling window \naqi_sb['five_day_average'] = rolling_average\n\n\n\nPlot\nAnd now we can plot! We are going to plot the five day average over the total data. We are going to do this using matplotlib.\n\n# Plot the data\nplt.plot(aqi_sb.index.values, aqi_sb['aqi'], color = \"blue\")\nplt.plot(aqi_sb.index.values, aqi_sb['five_day_average'], color = \"orange\")\nplt.xticks(rotation=45)\nplt.title(\"AQI in Santa Barbara during the Thomas Fire\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"AQI\")\nplt.legend(['Daily AQI', '5 day average'])"
  },
  {
    "objectID": "posts/2024-12-02-220-final/thomas_fire_blog_post.html#false-color-mapping-data-analysis",
    "href": "posts/2024-12-02-220-final/thomas_fire_blog_post.html#false-color-mapping-data-analysis",
    "title": "Thomas Fire analysis",
    "section": "False color mapping data analysis",
    "text": "False color mapping data analysis\nFor the next part of our analysis, we are going to use false color imagery to map the fire. To begin, we’re going to read in all of our data, both the landsat and fire perimeter data. For the landsat data, we use the os path for reproducibility’s sake.\n\n# Import landsat data\nfp = os.path.join('data','landsat8-2018-01-26-sb-simplified.nc')\nlandsat = rioxr.open_rasterio(fp)\n\n\n# Inspect the data\nlandsat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 25MB\nDimensions:      (band: 1, x: 870, y: 731)\nCoordinates:\n  * band         (band) int64 8B 1\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (band, y, x) float64 5MB ...\n    green        (band, y, x) float64 5MB ...\n    blue         (band, y, x) float64 5MB ...\n    nir08        (band, y, x) float64 5MB ...\n    swir22       (band, y, x) float64 5MB ...xarray.DatasetDimensions:band: 1x: 870y: 731Coordinates: (4)band(band)int641array([1])x(x)float641.213e+05 1.216e+05 ... 3.559e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., ..., 355395., 355665., 355935.])y(y)float643.952e+06 3.952e+06 ... 3.755e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., ..., 3755835., 3755565., 3755295.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]green(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]blue(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]nir08(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]swir22(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0, 122655.0, 122925.0,\n       123195.0, 123465.0, 123735.0,\n       ...\n       353505.0, 353775.0, 354045.0, 354315.0, 354585.0, 354855.0, 355125.0,\n       355395.0, 355665.0, 355935.0],\n      dtype='float64', name='x', length=870))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0, 3951045.0,\n       3950775.0, 3950505.0, 3950235.0, 3949965.0,\n       ...\n       3757725.0, 3757455.0, 3757185.0, 3756915.0, 3756645.0, 3756375.0,\n       3756105.0, 3755835.0, 3755565.0, 3755295.0],\n      dtype='float64', name='y', length=731))Attributes: (0)\n\n\nThe dimensions of the landsat data is (band:1, x:870, y:731). The variables included are the red, green, and blue band, as well as the near infrared and short wave infrared.\n\nlandsat.rio.crs\n\nCRS.from_epsg(32611)\n\n\nAdditionally, we see that the crs of the landsat is epsg: 32611. First, we are going to drop the band dimension from the landsat data, and then view the landsat data again to confirm that it was dropped.\n\n# Drop the band dimension from the data\nlandsat = landsat.squeeze(\"band\", drop=True)\n\n\n# Confirm that the band dimension was dropped\nlandsat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 25MB\nDimensions:      (x: 870, y: 731)\nCoordinates:\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (y, x) float64 5MB ...\n    green        (y, x) float64 5MB ...\n    blue         (y, x) float64 5MB ...\n    nir08        (y, x) float64 5MB ...\n    swir22       (y, x) float64 5MB ...xarray.DatasetDimensions:x: 870y: 731Coordinates: (3)x(x)float641.213e+05 1.216e+05 ... 3.559e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., ..., 355395., 355665., 355935.])y(y)float643.952e+06 3.952e+06 ... 3.755e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., ..., 3755835., 3755565., 3755295.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]green(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]blue(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]nir08(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]swir22(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]Indexes: (2)xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0, 122655.0, 122925.0,\n       123195.0, 123465.0, 123735.0,\n       ...\n       353505.0, 353775.0, 354045.0, 354315.0, 354585.0, 354855.0, 355125.0,\n       355395.0, 355665.0, 355935.0],\n      dtype='float64', name='x', length=870))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0, 3951045.0,\n       3950775.0, 3950505.0, 3950235.0, 3949965.0,\n       ...\n       3757725.0, 3757455.0, 3757185.0, 3756915.0, 3756645.0, 3756375.0,\n       3756105.0, 3755835.0, 3755565.0, 3755295.0],\n      dtype='float64', name='y', length=731))Attributes: (0)\n\n\nFor our first plot, a true color plot, we are going to select the red, green and blue variables in that order and then convert it to a numpy.array. Then, we will plot it.\n\n# Use robust parameter to update scale for the plot\nlandsat[['red','green','blue']].to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\nNow, we are going to read in the Thomas Fire Boundary data. In order to make sure we are able to later convert the crs to match that of the landsat data, we will assign it a preliminary crs.\n\n# Read in thomas_boundary in this notebook from data folder\nthomas_boundary = gpd.read_file('data/Thomas_Fire_boundary.shp').set_crs(epsg=32611)\n\n\n# Make sure that the thomas fire boundary and the landsat data are the same CRS\nthomas_boundary = thomas_boundary.to_crs(landsat.rio.crs)\nlandsat.rio.crs == thomas_boundary.crs\n\nTrue\n\n\n\n# Create a map with the false color image (like the one above) and the Thomas Fire perimeter\nfig, ax = plt.subplots(figsize=(10,10))\n\nlandsat[['swir22','nir08','red']].to_array().plot.imshow(ax=ax,\n                                                         robust=True)\n\nthomas_boundary.boundary.plot(ax=ax,\n                    color=\"red\")\n\nax.set_title(\"Thomas Fire (2017)\")\nax.legend(\"Thomas fire boundary\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\nSources\nMicrosoft. Landsat C2 L2. Microsoft Planetary Computer. Retrieved November 12, 2024, from https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2\nUnited States Environmental Protection Agency. (n.d.). Daily Air Quality Index (AQI) . EPA. https://aqs.epa.gov/aqsweb/airdata/download_files.html#AQI\nU.S. Department of Homeland Security. (n.d.). California fire perimeters (All) [Data set]. Data.gov. https://catalog.data.gov/dataset/california-fire-perimeters-all-b3436"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Elizabeth (Liz) Peterson",
    "section": "",
    "text": "Hi, welcome to my website! I’m Liz Peterson. I am currently a Master’s student at the University of California - Santa Barbara pursuing a degree in Environmental Data Science. I graduated from the University of Virginia (2024) with a Bachelor’s degree in Environmental Science and a minor in Data Science.\nI have a passion for climate justice as a way to help those who are disproportionately affected by climate change. I love pursuing a degree that gives me the technical skills to use data to advocate for our planet. Check out my about page to learn more about me, or take a look at my blog!"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "Analyzing weather trends in Minnesota\n\n\n\nQuarto\n\n\nMEDS\n\n\n\nFollowing extreme weather events at the Minneapolis-Saint Paul International Airport\n\n\n\nLiz Peterson\n\n\nDec 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThomas Fire analysis\n\n\nAnalyzing the 2017 Thomas Fire through Air Quality Index analysis and false color image analysis\n\n\n\nLiz Peterson\n\n\nDec 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to get from Falls Church, VA to Santa Barbara, CA\n\n\n\nQuarto\n\n\nMEDS\n\n\neds-296\n\n\n\nThere’s a suprising amount of space in this country\n\n\n\nLiz Peterson\n\n\nOct 18, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  }
]