[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Masters of Environmental Data Science (Bren School of Environmental Science and Management at UCSB 2025)\nBachelors of Arts in Environmental Science with a Minor in Data Science (UVA 2024)"
  },
  {
    "objectID": "about.html#my-education",
    "href": "about.html#my-education",
    "title": "About",
    "section": "",
    "text": "Masters of Environmental Data Science (Bren School of Environmental Science and Management at UCSB 2025)\nBachelors of Arts in Environmental Science with a Minor in Data Science (UVA 2024)"
  },
  {
    "objectID": "about.html#my-work",
    "href": "about.html#my-work",
    "title": "About",
    "section": "My work",
    "text": "My work\nDuring my undergraduate career, I worked for the Charlottesville Community Climate Collaborative as a Climate Justice Ambassador. My small group of Ambassadors conducted a study on natural gas use in Charlottesville, engaging with community members to explore the impacts of energy cost on their daily lives.\nOn campus, I logged 268 hours volunteering at HelpLine, a student-run crisis hotline, as both a volunteer and a trainer.\nI also worked for the Contemplative Sciences Center at UVA, where I dedicated time to helping students and faculty access resources to thrive internally."
  },
  {
    "objectID": "about.html#my-fun",
    "href": "about.html#my-fun",
    "title": "About",
    "section": "My fun",
    "text": "My fun\nKendama\nBig foot statues\nGood reads and letterboxd"
  },
  {
    "objectID": "posts/2024-10-18-my-first-post/index.html",
    "href": "posts/2024-10-18-my-first-post/index.html",
    "title": "How to get from Falls Church, VA to Santa Barbara, CA",
    "section": "",
    "text": "Have you ever asked yourself, how would I go about getting from Falls Church, Virginia to Santa Barbara, California? As a young woman experiencing her assent into adulthood, I too was faced with this age old question. To save you the trouble, I will share what I learned on this quest."
  },
  {
    "objectID": "posts/2024-10-18-my-first-post/index.html#from-virginia-to-minnesota-i-cant-offer-much-more-than-this",
    "href": "posts/2024-10-18-my-first-post/index.html#from-virginia-to-minnesota-i-cant-offer-much-more-than-this",
    "title": "How to get from Falls Church, VA to Santa Barbara, CA",
    "section": "From Virginia to Minnesota, I can’t offer much more than this",
    "text": "From Virginia to Minnesota, I can’t offer much more than this\nThis drive is all to familiar to me, so I offer only this."
  },
  {
    "objectID": "posts/2024-10-18-my-first-post/index.html#corn-palace",
    "href": "posts/2024-10-18-my-first-post/index.html#corn-palace",
    "title": "How to get from Falls Church, VA to Santa Barbara, CA",
    "section": "CORN PALACE",
    "text": "CORN PALACE\nAs a Midwesterner at heart, and a long time admirer of the butter sculpture at the Minnesota State Fair, this palace of corn appealed to me greatly."
  },
  {
    "objectID": "posts/2024-10-18-my-first-post/index.html#mount-rushmore",
    "href": "posts/2024-10-18-my-first-post/index.html#mount-rushmore",
    "title": "How to get from Falls Church, VA to Santa Barbara, CA",
    "section": "MOUNT RUSHMORE",
    "text": "MOUNT RUSHMORE\nIt’s quite peculiar. You think that there might some big monumental moment (pun intended), but there’s not. It really is just 4 heads carved into this rock! However, it is very beautiful. Maybe just a bit smaller than anticipated."
  },
  {
    "objectID": "posts/2024-10-18-my-first-post/index.html#arches-national-park",
    "href": "posts/2024-10-18-my-first-post/index.html#arches-national-park",
    "title": "How to get from Falls Church, VA to Santa Barbara, CA",
    "section": "ARCHES NATIONAL PARK",
    "text": "ARCHES NATIONAL PARK\nIt’s hard to describe the elation I felt running around on these red rocks after so many days in the car. I felt like I was nearly bouncing."
  },
  {
    "objectID": "posts/2024-10-18-my-first-post/index.html#grand-canyon",
    "href": "posts/2024-10-18-my-first-post/index.html#grand-canyon",
    "title": "How to get from Falls Church, VA to Santa Barbara, CA",
    "section": "GRAND CANYON",
    "text": "GRAND CANYON\nIt truly is grand. As we were approaching, we saw a lot of canyons. We kept asking ourselves… is that it? Are we sure we’re going to know when we’re there? We certainly did. It’s quite unmissable."
  },
  {
    "objectID": "posts/2024-10-18-my-first-post/index.html#we-made-it",
    "href": "posts/2024-10-18-my-first-post/index.html#we-made-it",
    "title": "How to get from Falls Church, VA to Santa Barbara, CA",
    "section": "We made it",
    "text": "We made it\nBoy oh boy was I nervous to see this sign. I’m not sure that those nerves subsided for a couple of days. But look at us now :)"
  },
  {
    "objectID": "posts/2024-12-13-msp-weather/index.html",
    "href": "posts/2024-12-13-msp-weather/index.html",
    "title": "Analyzing weather trends in Minnesota",
    "section": "",
    "text": "On Halloween 1991, a massive blizzard hit Minnesota. This event has lived on in cultural infamy among Minnesotans. Of the 25 top snowfall events in Minnesota (from 1884-2023), only 5 of them occurred in the 21st century. There seems to be a trend away from high intensity snowfall events. This is a curious question: as the onset of climate change raises temperatures and increases the occurrence of extreme weather events, what does this mean for blizzards and intense snowfall events? Are there fewer intense snowfall events? Is that correlated to an increase in atmospheric CO2? And, if so, does that align with other trends we see in weather patterns?\nAs the general public becomes more worried about the reality of what a warming planet means for them, more research about how climate change might influence weather patterns is being conducted. There are studies analyzing what a warmer planet means for snowfall events, but these are mostly looking at worldwide trends. This analysis aims to see how this is working in Minnesota, a place where snow has a lot of cultural meaning."
  },
  {
    "objectID": "posts/2024-12-13-msp-weather/index.html#introduction",
    "href": "posts/2024-12-13-msp-weather/index.html#introduction",
    "title": "Analyzing weather trends in Minnesota",
    "section": "",
    "text": "On Halloween 1991, a massive blizzard hit Minnesota. This event has lived on in cultural infamy among Minnesotans. Of the 25 top snowfall events in Minnesota (from 1884-2023), only 5 of them occurred in the 21st century. There seems to be a trend away from high intensity snowfall events. This is a curious question: as the onset of climate change raises temperatures and increases the occurrence of extreme weather events, what does this mean for blizzards and intense snowfall events? Are there fewer intense snowfall events? Is that correlated to an increase in atmospheric CO2? And, if so, does that align with other trends we see in weather patterns?\nAs the general public becomes more worried about the reality of what a warming planet means for them, more research about how climate change might influence weather patterns is being conducted. There are studies analyzing what a warmer planet means for snowfall events, but these are mostly looking at worldwide trends. This analysis aims to see how this is working in Minnesota, a place where snow has a lot of cultural meaning."
  },
  {
    "objectID": "posts/2024-12-13-msp-weather/index.html#data-details",
    "href": "posts/2024-12-13-msp-weather/index.html#data-details",
    "title": "Analyzing weather trends in Minnesota",
    "section": "Data details",
    "text": "Data details\nTo examine these questions, we will need to gather some important data: extensive weather and precipitation data from Minnesota, atmospheric CO2 concentration data, and some information about specific snowfall events.\nThe precipitation data came from NOAA’s National Centers for Environmental Information. While this platform has a huge volume of data from all over, you are only allowed to request said data in 10 year chunks. Therefore, the chunks of data I downloaded were: 1985/01/01 - 1994/01/01, 1994/01/02 - 2003/12/31, 2004/01/01 - 2013/12/31, and 2014/01/01 - 2023/12/31. The weather station where the data was recorded was the Minneapolis Saint Paul international airport, which is located in Southeast Minnesota.\nThe emissions data comes from an R package called hockeystick. The package is very robust with all sorts of climate adjacent information. This includes atmospheric CO2, methane, emissions, instrumental and proxy temperature records, sea levels, Arctic/Antarctic sea-ice, Hurricanes, and Paleo climate data."
  },
  {
    "objectID": "posts/2024-12-13-msp-weather/index.html#analysis",
    "href": "posts/2024-12-13-msp-weather/index.html#analysis",
    "title": "Analyzing weather trends in Minnesota",
    "section": "Analysis",
    "text": "Analysis"
  },
  {
    "objectID": "posts/2024-12-13-msp-weather/index.html#results",
    "href": "posts/2024-12-13-msp-weather/index.html#results",
    "title": "Analyzing weather trends in Minnesota",
    "section": "Results",
    "text": "Results\n\n# Load required packages\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/elizabethpeterson/Downloads/MEDS/egp4aq.github.io\n\nlibrary(ggplot2)\nlibrary(here)\nlibrary(hockeystick)\n\nhockeystick 0.8.5: Use hockeystick_cache_details() to view cached climate data.\nhockeystick 0.8.5: Use hockeystick_update_all() to update and cache all climate data.\n\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(broom)\n\n\n# Read in data\n\n# 1985/01/01 - 1994/01/01\nweather_1985_1994 &lt;- read_csv(here('posts/2024-12-13-msp-weather/data/85-94.csv')) %&gt;% # Read in csv\n  janitor::clean_names() %&gt;% # convert column names to lower snake case\n  select(station, date, hourly_precipitation) %&gt;% # select only columns we are interested in\n  mutate(hourly_precipitation = as.numeric(hourly_precipitation))\n\nNew names:\nRows: 86665 Columns: 124\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(9): REPORT_TYPE...3, SOURCE...4, HourlyPresentWeatherType, HourlySky... dbl\n(13): STATION, HourlyAltimeterSetting, HourlyDewPointTemperature, Hour... lgl\n(100): AWND, BackupDirection, BackupDistance, BackupDistanceUnit, Backu... dttm\n(1): DATE date (1): WindEquipmentChangeDate\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `REPORT_TYPE` -&gt; `REPORT_TYPE...3`\n• `SOURCE` -&gt; `SOURCE...4`\n• `REPORT_TYPE` -&gt; `REPORT_TYPE...96`\n• `SOURCE` -&gt; `SOURCE...97`\n\n# 1994/01/02 - 2003/12/31\nweather_1994_2003 &lt;- read_csv(here('posts/2024-12-13-msp-weather/data/94-03.csv')) %&gt;%\n  janitor::clean_names() %&gt;%\n  select(station, date, hourly_precipitation) %&gt;%\n  mutate(hourly_precipitation = as.numeric(hourly_precipitation))\n\nNew names:\n• `REPORT_TYPE` -&gt; `REPORT_TYPE...3`\n• `SOURCE` -&gt; `SOURCE...4`\n• `REPORT_TYPE` -&gt; `REPORT_TYPE...96`\n• `SOURCE` -&gt; `SOURCE...97`\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 141614 Columns: 124\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (19): REPORT_TYPE...3, SOURCE...4, DailyCoolingDegreeDays, DailyPeakWin...\ndbl  (64): STATION, AWND, CDSD, CLDD, DailyAverageDryBulbTemperature, DailyA...\nlgl  (27): BackupDirection, BackupDistance, BackupDistanceUnit, BackupElemen...\ndttm (13): DATE, ShortDurationEndDate005, ShortDurationEndDate010, ShortDura...\ndate  (1): WindEquipmentChangeDate\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `hourly_precipitation = as.numeric(hourly_precipitation)`.\nCaused by warning:\n! NAs introduced by coercion\n\n# 2004/01/01 - 2013/12/31\nweather_2004_2014 &lt;- read_csv(here('posts/2024-12-13-msp-weather/data/04-14.csv')) %&gt;%\n  janitor::clean_names() %&gt;%\n  select(station, date, hourly_precipitation) %&gt;%\n  mutate(hourly_precipitation = as.numeric(hourly_precipitation))\n\nNew names:\n• `REPORT_TYPE` -&gt; `REPORT_TYPE...3`\n• `SOURCE` -&gt; `SOURCE...4`\n• `REPORT_TYPE` -&gt; `REPORT_TYPE...96`\n• `SOURCE` -&gt; `SOURCE...97`\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 134637 Columns: 124\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (25): REPORT_TYPE...3, SOURCE...4, BackupDirection, BackupDistanceUnit,...\ndbl  (80): STATION, AWND, BackupDistance, BackupElevation, BackupLatitude, B...\nlgl   (5): BackupElevationUnit, DYHF, MonthlyAverageRH, MonthlyDewpointTempe...\ndttm (13): DATE, ShortDurationEndDate005, ShortDurationEndDate010, ShortDura...\ndate  (1): WindEquipmentChangeDate\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `hourly_precipitation = as.numeric(hourly_precipitation)`.\nCaused by warning:\n! NAs introduced by coercion\n\n# 2014/01/01 - 2023/12/31\nweather_2014_2023 &lt;- read_csv(here('posts/2024-12-13-msp-weather/data/14-23.csv')) %&gt;%\n  janitor::clean_names() %&gt;%\n  select(station, date, hourly_precipitation) %&gt;%\n  mutate(hourly_precipitation = as.numeric(hourly_precipitation))\n\nNew names:\n• `REPORT_TYPE` -&gt; `REPORT_TYPE...3`\n• `SOURCE` -&gt; `SOURCE...4`\n• `REPORT_TYPE` -&gt; `REPORT_TYPE...96`\n• `SOURCE` -&gt; `SOURCE...97`\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 224698 Columns: 124\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (21): REPORT_TYPE...3, BackupDirection, BackupDistanceUnit, BackupEleme...\ndbl  (80): STATION, SOURCE...4, AWND, BackupDistance, BackupLatitude, Backup...\nlgl   (9): BackupElevation, BackupElevationUnit, DYHF, MonthlyAverageRH, Mon...\ndttm (13): DATE, ShortDurationEndDate005, ShortDurationEndDate010, ShortDura...\ndate  (1): WindEquipmentChangeDate\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `hourly_precipitation = as.numeric(hourly_precipitation)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\n\n# First preliminary plot of 85 to 94 data\nggplot(weather_1985_1994, aes(date, hourly_precipitation)) +\n  geom_point()\n\nWarning: Removed 7754 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n# Aggregate data to get daily precipitation\ndaily_avg_1985_1994 &lt;- weather_1985_1994 %&gt;%\n  mutate(date = as.Date(date)) %&gt;%\n  group_by(date) %&gt;%\n  summarize(daily_avg_precip = mean(hourly_precipitation))\n\n\nggplot(daily_avg_1985_1994, aes(date, daily_avg_precip)) +\n  geom_point()\n\nWarning: Removed 1663 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nTry aggregating by month to get a longer term trend\n\n# Combine all datasets into one and add a period column\ncombined_weather_data &lt;- bind_rows(\n  weather_1985_1994 %&gt;% mutate(period = \"1985-1994\"),\n  weather_1994_2003 %&gt;% mutate(period = \"1994-2003\"),\n  weather_2004_2014 %&gt;% mutate(period = \"2004-2014\"),\n  weather_2014_2023 %&gt;% mutate(period = \"2014-2023\")\n)\n\n# Aggregate data to get monthly precipitation\nmonthly_avg_combined &lt;- combined_weather_data %&gt;%\n  mutate(date = as.Date(date),  # Ensure 'date' is in Date format\n         year_month = floor_date(date, \"month\")) %&gt;%  # Create year_month column --&gt; floor_date from lubridate\n  group_by(period, year_month) %&gt;%  # Group by both 'period' and 'year_month'\n  summarize(monthly_avg_precip = mean(hourly_precipitation, na.rm = TRUE))  # Calculate monthly average\n\n`summarise()` has grouped output by 'period'. You can override using the\n`.groups` argument.\n\n\n\n# Specify date of Halloween blizzard\nhighlight_date &lt;- as.Date(\"1991-10-31\")\n\n\n# Plot combined data\nggplot(monthly_avg_combined, aes(x = year_month, y = monthly_avg_precip, color = period)) +\n  geom_line() +\n  scale_x_date(date_labels = \"%b %Y\", date_breaks = \"18 months\") +  # Format x-axis labels\n  labs(title = \"Monthly Average Precipitation by Period\",\n    x = \"Date\",\n    y = \"Monthly Average Precipitation (mm)\",\n    color = \"Period\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  geom_vline(aes(xintercept = highlight_date), color = \"black\", linetype = \"dashed\", size = 0.3)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\nTesting for a trend over time\n\n# Fit a linear regression model to test if there is a significant trend over time\nlinear_model &lt;- lm(monthly_avg_precip ~ year_month, data = monthly_avg_combined)\n\n# View the summary of the model\nsummary(linear_model)\n\n\nCall:\nlm(formula = monthly_avg_precip ~ year_month, data = monthly_avg_combined)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.009292 -0.003686 -0.001414  0.001829  0.039200 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.925e-04  8.798e-04  -0.332     0.74    \nyear_month   4.911e-07  6.649e-08   7.387 6.98e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.00592 on 467 degrees of freedom\nMultiple R-squared:  0.1046,    Adjusted R-squared:  0.1027 \nF-statistic: 54.56 on 1 and 467 DF,  p-value: 6.98e-13\n\n\n\n# Add the fitted line to the plot\nggplot(monthly_avg_combined, aes(x = year_month, y = monthly_avg_precip)) +\n  geom_point() +  # Scatter plot of the data\n  geom_smooth(method = \"lm\", se = FALSE, aes()) +  # Linear model line\n  labs(title = \"Monthly Average Precipitation with Trend\",\n    x = \"Date\",\n    y = \"Monthly Average Precipitation (mm)\",\n    color = \"Period\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nUse hockeystick data for emissions\n\nemissions &lt;- get_emissions()\n\n\nus_emissions &lt;- emissions %&gt;%\n  filter(country == \"United States\") %&gt;%\n  filter(year &gt;= 1985 & year &lt;= 2023)\n\n\nggplot(us_emissions, aes(x = year, y = co2)) +\n  geom_line() +\n  theme_minimal() +\n  labs(title = \"Annual CO2 Emissions\",\n    x = \"Year\",\n    y = \"CO2 Emissions (million metric tons)\")"
  },
  {
    "objectID": "posts/2024-12-13-msp-weather/index.html#real-analysis-for-co2-and-weather",
    "href": "posts/2024-12-13-msp-weather/index.html#real-analysis-for-co2-and-weather",
    "title": "Analyzing weather trends in Minnesota",
    "section": "REAL ANALYSIS FOR CO2 AND WEATHER",
    "text": "REAL ANALYSIS FOR CO2 AND WEATHER\n\nMerge precipitation data with CO2 emission data\n\n#  aggregate the monthly precipitation data to be yearly data so we can merge it with the yearly us emissions data\nyearly_avg_precip &lt;- monthly_avg_combined %&gt;%\n  mutate(year = as.numeric(format(year_month, \"%Y\"))) %&gt;%\n  group_by(year) %&gt;%\n  summarize(yearly_avg_precip = mean(monthly_avg_precip, na.rm = TRUE))\n\n\n# merge the us_emissions data and the precipitation data and get rid of the columns we don't need\nprecip_emissions &lt;- left_join(yearly_avg_precip, us_emissions, by = \"year\") %&gt;%\n  select(year, yearly_avg_precip, country, co2)\n\nIn order to visualize the relationship between the yearly average precipitation and atmospheric co2, we need to use a gamma regression rather than the classic linear regression.\n\n# Gamma regression\ngamma_model &lt;- glm(yearly_avg_precip ~ co2, data = precip_emissions, family = Gamma(link = \"log\"))\nsummary(gamma_model)\n\n\nCall:\nglm(formula = yearly_avg_precip ~ co2, family = Gamma(link = \"log\"), \n    data = precip_emissions)\n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -5.8291922  0.9087131  -6.415 1.73e-07 ***\nco2          0.0001275  0.0001666   0.765    0.449    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.1930582)\n\n    Null deviance: 7.5846  on 38  degrees of freedom\nResidual deviance: 7.4795  on 37  degrees of freedom\nAIC: -354.55\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n# Plot the data with regression line\nggplot(precip_emissions, aes(x = co2, y = yearly_avg_precip)) +\n  geom_point() +\n  geom_smooth(method = \"glm\", \n              method.args = list(family = Gamma(link = \"log\")), \n              se = FALSE, \n              color = \"blue\") +\n  labs(title = \"Linear Relationship between CO2 Emissions and Precipitation\",\n    x = \"CO2 Emissions (million metric tons)\",\n    y = \"Yearly Average Precipitation (mm)\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "posts/2024-12-13-msp-weather/index.html#hypothesis-testing",
    "href": "posts/2024-12-13-msp-weather/index.html#hypothesis-testing",
    "title": "Analyzing weather trends in Minnesota",
    "section": "Hypothesis testing",
    "text": "Hypothesis testing\n\nFormulate hypotheses\nNow that we have our model, we will utilize hypothesis testing to evaluate how much we can rely on this model. To hypothesize on our gamma model, we will begin by formulating null and alternate hypotheses. The null hypothesis (or H0) is that there is no relationship between atmospheric co2 and precipitation, or in other words, the slope of the regression line is zero. The alternative hypothesis (or H1) is that there is a significant relationship between atmospheric co2 and precipitation, or in other words, the slope of the regression line is not zero.\nTo\n\n# Fit a linear regression model\nregression_model &lt;- lm(yearly_avg_precip ~ co2, data = precip_emissions)\nresults &lt;- tidy(regression_model)\n\n\nresults %&gt;%\n  kable(\"html\", caption = \"Regression Model Results\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), full_width = FALSE)\n\n\nRegression Model Results\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.0020938\n0.0053196\n0.3935935\n0.6961403\n\n\nco2\n0.0000007\n0.0000010\n0.7159502\n0.4785165\n\n\n\n\n\n\n\nwhen we run this, we get 0.479 as the p value for the co2 variable. this is much higher than 0.05, which means we cannot reject the null hypothesis. for the full model significance, we have a p value of 0.4785 which is also not statistically significant.\n\nconfint(regression_model)\n\n                    2.5 %       97.5 %\n(Intercept) -8.684769e-03 1.287229e-02\nco2         -1.277878e-06 2.674409e-06\n\n\nwhen we run our confidence interval for the intercept, we get [-0.008684769, 0.01287229] (for a 2.5%/97.5% split). this means that we can be 97.5% sure that the true intercept falls within that range. More importantly for our co2 variable we get [-1.277878e-06, 2.674409e-06]. This means that we are 97.5% confident that the true slope of the linear regression line for co2 is between that range, which includes zero. this simply further proves taht the slope is not significantly different from zero.\n\n\nSources\nhttps://www.twincities.com/2021/10/29/remembering-the-1991-halloween-blizzard/ accessed 12/10"
  },
  {
    "objectID": "posts/2024-12-02-220-final/thomas_fire_blog_post.html",
    "href": "posts/2024-12-02-220-final/thomas_fire_blog_post.html",
    "title": "Thomas Fire analysis",
    "section": "",
    "text": "The Thomas Fire of December 2017 burned approximately 440 miles squared in Ventura and Santa Barbara counties. It was not fully contained until the the middle of January 2018. This fire had huge implications, as it displaced over 100,000 southern California residents, required the largest deployment of firefighters in California history to combat a wildfire, and cost over $200 million to fight.\nTo analyze the impact of the wildfire, we will look into the implications for air quality in the surrounding areas and how the vegetation was impacted using false color imagery.\n\n\n\nthomas_fire_picture.jpg"
  },
  {
    "objectID": "posts/2024-12-02-220-final/thomas_fire_blog_post.html#air-quality-index-data-analysis",
    "href": "posts/2024-12-02-220-final/thomas_fire_blog_post.html#air-quality-index-data-analysis",
    "title": "Thomas Fire analysis",
    "section": "Air Quality Index data analysis",
    "text": "Air Quality Index data analysis\nBefore we do any analysis, our first step is always to read in our necessary libraries\n\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\nimport xarray as xr\nimport rioxarray as rioxr\n\nFor the AQI data, we are going to read in the csv files directly from their url.\n\naqi_17 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\", compression='zip')\naqi_18 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\", compression='zip')\n\nNow we can do our analysis! This first part includes cleaning the aqi data, evaluating the rolling average, and plotting our results.\n\nCombine and clean data\nFirst, we bring together our dataframes from 2017 and 2018. Then we clean the column names by putting them all in lower snake case. Finally, we filter the data to only Santa Barbara and drop unnecessary columns.\n\n# Use the concat() function to combine the two dataframes\naqi = pd.concat([aqi_17, aqi_18])\n\n# Simplify column names\naqi.columns = (aqi.columns\n                  .str.lower()\n                  .str.replace(' ','_'))\n\n# Filter to data only from Santa Barbara county\naqi_sb = aqi[aqi['county_name'] == 'Santa Barbara']\n# Drop state_name, county_name, state_code, and county_code columns from dataframe\naqi_sb = aqi.drop(['state_name','county_name','state_code','county_code'], axis = 1)\n\n\n\nTake rolling average of AQI data\nNext, we put the date as the index of our dataframe so that we can use the index to take a rolling average over five days.\n\n# Convert 'date' column to be of type datetime\naqi_sb.date = pd.to_datetime(aqi_sb['date'])\naqi_sb = aqi_sb.set_index('date')\n\n# Calculate AQI rolling average over 5 days\naqi_sb = aqi_sb.sort_index(ascending=False)\nrolling_average = aqi_sb['aqi'].rolling('5D').mean()\n\n# Add a new column which includes the mean AQI for the 5 day rolling window \naqi_sb['five_day_average'] = rolling_average\n\n\n\nPlot\nAnd now we can plot! We are going to plot the five day average over the total data.\n\n# Plot aqi and five_day_average\nplt.figure(figsize=(10,8))\nplt.plot(aqi_sb.index.values,\n         aqi_sb['aqi'],\n         color = \"orange\")\nplt.plot(aqi_sb.index.values,\n         aqi_sb['five_day_average'],\n         color = \"blue\")\nplt.xticks(rotation = 45)\nplt.xlabel(\"Date\")\nplt.ylabel(\"AQI\")\nplt.title(\"Santa Barbara AQI (2017-2018)\")\n\nText(0.5, 1.0, 'Santa Barbara AQI (2017-2018)')"
  },
  {
    "objectID": "posts/2024-12-02-220-final/thomas_fire_blog_post.html#false-color-mapping-data-analysis",
    "href": "posts/2024-12-02-220-final/thomas_fire_blog_post.html#false-color-mapping-data-analysis",
    "title": "Thomas Fire analysis",
    "section": "False color mapping data analysis",
    "text": "False color mapping data analysis\nFor the next part of our analysis, we are going to use false color imagery to map the fire. To begin, we’re going to read in all of our data, both the landsat and fire perimeter data.\n\n# Import landsat data\nfp = os.path.join('data','landsat8-2018-01-26-sb-simplified.nc')\nlandsat = rioxr.open_rasterio(fp)\n# Read in thomas_boundary in this notebook from data folder\nthomas_boundary = gpd.read_file('data/Thomas_Fire_boundary.shp')\n\nWe also want to make sure that our data are in the same format so that we can manipulate them.\n\n# Make sure that the thomas fire boundary and the landsat data are the same CRS\nthomas_boundary = thomas_boundary.to_crs(landsat.rio.crs)\nlandsat.rio.crs == thomas_boundary.crs\n\nTrue\n\n\nBefore we look into the landsat data, let’s plot the Thomas fire boundary to see what it looks like.\n\n# Plot boundary to see what it looks like\nthomas_boundary.plot()\n\n\n\n\n\n\n\n\nFirst, we are going to drop the band dimension from the data and then select the desired variables.\n\n# Drop the band dimension from the data\nlandsat = landsat.squeeze(\"band\", drop=True)\n\nFirst, we make a true color image!\n\n# Use robust parameter to update scale for the plot\nlandsat[['red','green','blue']].to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\nNow, we will create a false color image and layer on top the Thomas boundary!\n\n# Create a map with the false color image (like the one above) and the Thomas Fire perimeter\nfig, ax = plt.subplots(figsize=(10,10))\n\nlandsat[['swir22','nir08','red']].to_array().plot.imshow(ax=ax, robust=True)\n\nthomas_boundary.boundary.plot(ax=ax,\n                    color=\"red\")\n\nax.set_title(\"Thomas Fire (2017)\")\nax.legend(\"Thomas Fire\")\n\nplt.show"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Elizabeth (Liz) Peterson",
    "section": "",
    "text": "Hi, welcome to my website! I’m Liz Peterson. I am currently a Master’s student at the University of California - Santa Barbara pursuing a degree in Environmental Data Science. I graduated from the University of Virginia (2024) with a Bachelor’s degree in Environmental Science and a minor in Data Science.\nI have a passion for climate justice as a way to help those who are disproportionately affected by climate change. I love pursuing a degree that gives me the technical skills to use data to advocate for our planet. Check out my about page to learn more about me, or take a look at my blog!"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "Analyzing weather trends in Minnesota\n\n\n\nQuarto\n\n\nMEDS\n\n\n\nFollowing extreme weather events at the Minneapolis-Saint Paul International Airport\n\n\n\nLiz Peterson\n\n\nDec 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThomas Fire analysis\n\n\nAnalyzing the 2017 Thomas Fire through Air Quality Index analysis and false color image analysis\n\n\n\nLiz Peterson\n\n\nDec 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to get from Falls Church, VA to Santa Barbara, CA\n\n\n\nQuarto\n\n\nMEDS\n\n\neds-296\n\n\n\nThere’s a suprising amount of space in this country\n\n\n\nLiz Peterson\n\n\nOct 18, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  }
]